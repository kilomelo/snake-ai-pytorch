{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pygame\n",
    "import random\n",
    "from enum import Enum\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "\n",
    "# pygame.init()\n",
    "# font = pygame.font.Font('arial.ttf', 25)\n",
    "\n",
    "class Direction(Enum):\n",
    "    RIGHT = 1\n",
    "    LEFT = 2\n",
    "    UP = 3\n",
    "    DOWN = 4\n",
    "\n",
    "Point = namedtuple('Point', 'x, y')\n",
    "\n",
    "# game graphic\n",
    "HEAD = \"@\"\n",
    "WALL = \"#\"\n",
    "BODY = \"O\"\n",
    "FOOD = \"*\"\n",
    "\n",
    "class SnakeGame:\n",
    "    def __init__(self, width, height):\n",
    "        self.map = np.zeros((width, height))\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        # init display\n",
    "        # self.display = pygame.display.set_mode((self.w, self.h))\n",
    "        # pygame.display.set_caption('Snake')\n",
    "        # self.clock = pygame.time.Clock()\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.map[:, :] = 0\n",
    "        self.direction = Direction.RIGHT\n",
    "        self.head = Point(self.width // 2, self.height // 2)\n",
    "        self.snake = [\n",
    "            self.head,\n",
    "            Point(self.head.x - 1, self.head.y),\n",
    "            Point(self.head.x - 2, self.head.y)\n",
    "        ]\n",
    "        self.map[self.head.x, self.head.y] = 1\n",
    "        for body in self.snake[1:]:\n",
    "            self.map[body.x, body.y] = 2\n",
    "        self.score = 0\n",
    "        self.food = None\n",
    "        self._place_food()\n",
    "        self.frame_iteration = 0\n",
    "\n",
    "    def _place_food(self):\n",
    "        x = random.randint(0, self.width - 1) \n",
    "        y = random.randint(0, self.height - 1)\n",
    "        self.food = Point(x, y)\n",
    "        if self.food in self.snake:\n",
    "            self._place_food()\n",
    "        else:\n",
    "            self.map[self.food.x, self.food.y] = 3\n",
    "\n",
    "    def play_step(self, action):\n",
    "        self.frame_iteration += 1\n",
    "\n",
    "        # 2. move\n",
    "        self._move(action) # update the head\n",
    "        self.snake.insert(0, self.head)\n",
    "\n",
    "        # 3. check if game over\n",
    "        reward = 0\n",
    "        game_over = False\n",
    "        if self.is_collision() or self.frame_iteration > 100*len(self.snake):\n",
    "            game_over = True\n",
    "            reward = -10\n",
    "            return reward, game_over, self.score\n",
    "        \n",
    "        self.map[self.head.x, self.head.y] = 1\n",
    "        \n",
    "        # 4. place new food or just move\n",
    "        if self.head == self.food:\n",
    "            self.score += 1\n",
    "            reward = 10\n",
    "            self._place_food()\n",
    "        else:\n",
    "            tail = self.snake.pop()\n",
    "            self.map[tail.x, tail.y] = 0\n",
    "\n",
    "        # 6. return game over and score\n",
    "        return reward, game_over, self.score\n",
    "\n",
    "    def is_collision(self, pt=None):\n",
    "        if pt is None:\n",
    "            pt = self.head\n",
    "        # hits boundary\n",
    "        if pt.x >= self.width or pt.x < 0 or pt.y >= self.height or pt.y < 0:\n",
    "            return True\n",
    "        # hits itself\n",
    "        if pt in self.snake[1:]:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "    \n",
    "    def render(self):\n",
    "        for h in range(self.height + 2):\n",
    "            for w in range(self.width + 2):\n",
    "                p = Point(w - 1, h - 1)\n",
    "                if w == 0 or w == self.width + 1 or h == 0 or h == self.height + 1:\n",
    "                    print(WALL, end = \"\\n\" if w == self.width + 1 else \"\")\n",
    "                elif self.map[p.x, p.y] == 1:\n",
    "                    print(HEAD, end=\"\")\n",
    "                elif self.map[p.x, p.y] == 2:\n",
    "                    print(BODY, end=\"\")\n",
    "                elif self.map[p.x, p.y] == 3:\n",
    "                    print(FOOD, end=\"\")\n",
    "                else:\n",
    "                    print(\" \", end=\"\")\n",
    "\n",
    "    def _move(self, action):\n",
    "        # [straight, right, left]\n",
    "\n",
    "        clock_wise = [Direction.RIGHT, Direction.DOWN, Direction.LEFT, Direction.UP]\n",
    "        idx = clock_wise.index(self.direction)\n",
    "\n",
    "        if np.array_equal(action, [1, 0, 0]):\n",
    "            new_dir = clock_wise[idx] # no change\n",
    "        elif np.array_equal(action, [0, 1, 0]):\n",
    "            next_idx = (idx + 1) % 4\n",
    "            new_dir = clock_wise[next_idx] # right turn r -> d -> l -> u\n",
    "        else: # [0, 0, 1]\n",
    "            next_idx = (idx - 1) % 4\n",
    "            new_dir = clock_wise[next_idx] # left turn r -> u -> l -> d\n",
    "\n",
    "        self.direction = new_dir\n",
    "\n",
    "        x = self.head.x\n",
    "        y = self.head.y\n",
    "        self.map[x, y] = 2\n",
    "        if self.direction == Direction.RIGHT:\n",
    "            x += 1\n",
    "        elif self.direction == Direction.LEFT:\n",
    "            x -= 1\n",
    "        elif self.direction == Direction.DOWN:\n",
    "            y += 1\n",
    "        elif self.direction == Direction.UP:\n",
    "            y -= 1\n",
    "\n",
    "        self.head = Point(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "from model import Linear_QNet, QTrainer\n",
    "from helper import plot\n",
    "\n",
    "MAX_MEMORY = 100_000\n",
    "BATCH_SIZE = 1000\n",
    "LR = 0.001\n",
    "\n",
    "class Agent:\n",
    "\n",
    "    def __init__(self, game):\n",
    "        self.n_games = 0\n",
    "        self.epsilon = 0 # randomness\n",
    "        self.gamma = 0.9 # discount rate\n",
    "        self.memory = deque(maxlen=MAX_MEMORY) # popleft()\n",
    "        self.model = Linear_QNet(game.width * game.height, 256, 3)\n",
    "        self.trainer = QTrainer(self.model, lr=LR, gamma=self.gamma)\n",
    "\n",
    "    def get_state(self, game):\n",
    "        return game.map.flatten()\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done)) # popleft if MAX_MEMORY is reached\n",
    "\n",
    "    def train_long_memory(self):\n",
    "        if len(self.memory) > BATCH_SIZE:\n",
    "            mini_sample = random.sample(self.memory, BATCH_SIZE) # list of tuples\n",
    "        else:\n",
    "            mini_sample = self.memory\n",
    "\n",
    "        states, actions, rewards, next_states, dones = zip(*mini_sample)\n",
    "        self.trainer.train_step(states, actions, rewards, next_states, dones)\n",
    "        #for state, action, reward, nexrt_state, done in mini_sample:\n",
    "        #    self.trainer.train_step(state, action, reward, next_state, done)\n",
    "\n",
    "    def train_short_memory(self, state, action, reward, next_state, done):\n",
    "        self.trainer.train_step(state, action, reward, next_state, done)\n",
    "\n",
    "    def get_action(self, state):\n",
    "        # random moves: tradeoff exploration / exploitation\n",
    "        self.epsilon = 80 - self.n_games\n",
    "        final_move = [0,0,0]\n",
    "        if random.randint(0, 200) < self.epsilon:\n",
    "            move = random.randint(0, 2)\n",
    "            final_move[move] = 1\n",
    "        else:\n",
    "            state0 = torch.tensor(state, dtype=torch.float)\n",
    "            prediction = self.model(state0)\n",
    "            move = torch.argmax(prediction).item()\n",
    "            final_move[move] = 1\n",
    "\n",
    "        return final_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def train():\n",
    "    plot_scores = []\n",
    "    plot_mean_scores = []\n",
    "    total_score = 0\n",
    "    record = 0\n",
    "    game = SnakeGame(16, 9)\n",
    "    agent = Agent(game)\n",
    "    while True:\n",
    "        # get old state\n",
    "        state_old = agent.get_state(game)\n",
    "\n",
    "        # get move\n",
    "        final_move = agent.get_action(state_old)\n",
    "\n",
    "        # perform move and get new state\n",
    "        reward, done, score = game.play_step(final_move)\n",
    "\n",
    "        # clear_output(wait=True)\n",
    "        # game.render()\n",
    "        # time.sleep(0.01)\n",
    "\n",
    "        state_new = agent.get_state(game)\n",
    "\n",
    "        # train short memory\n",
    "        agent.train_short_memory(state_old, final_move, reward, state_new, done)\n",
    "\n",
    "        # remember\n",
    "        agent.remember(state_old, final_move, reward, state_new, done)\n",
    "\n",
    "        if done:\n",
    "            # train long memory, plot result\n",
    "            game.reset()\n",
    "            agent.n_games += 1\n",
    "            agent.train_long_memory()\n",
    "\n",
    "            if score > record:\n",
    "                record = score\n",
    "                agent.model.save()\n",
    "\n",
    "            print('Game', agent.n_games, 'Score', score, 'Record:', record)\n",
    "\n",
    "            plot_scores.append(score)\n",
    "            total_score += score\n",
    "            # mean_score = total_score / agent.n_games\n",
    "            mean_score = average_of_last_n_items(plot_scores, 20)\n",
    "            plot_mean_scores.append(mean_score)\n",
    "            # plot(plot_scores, plot_mean_scores)\n",
    "        \n",
    "\n",
    "def average_of_last_n_items(lst, n):\n",
    "    # 边界情况：当n为0或负数时，返回None\n",
    "    if n <= 0:\n",
    "        return None\n",
    "    \n",
    "    # 边界情况：当列表为空时，返回None\n",
    "    if not lst:\n",
    "        return None\n",
    "\n",
    "    # 如果n大于列表的长度，使用整个列表\n",
    "    n = min(n, len(lst))\n",
    "    \n",
    "    # 使用切片获取末尾n项，并计算平均值\n",
    "    return sum(lst[-n:]) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32md:\\Dev\\study\\snake-ai-pytorch\\the_game.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/study/snake-ai-pytorch/the_game.ipynb#X13sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     \u001b[39mif\u001b[39;00m event\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m pygame\u001b[39m.\u001b[39mQUIT:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/study/snake-ai-pytorch/the_game.ipynb#X13sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m         pygame\u001b[39m.\u001b[39mquit()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Dev/study/snake-ai-pytorch/the_game.ipynb#X13sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m update_ui(game)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/study/snake-ai-pytorch/the_game.ipynb#X13sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/study/snake-ai-pytorch/the_game.ipynb#X13sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m# get old state\u001b[39;00m\n",
      "\u001b[1;32md:\\Dev\\study\\snake-ai-pytorch\\the_game.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/study/snake-ai-pytorch/the_game.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_ui\u001b[39m(game):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Dev/study/snake-ai-pytorch/the_game.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     display\u001b[39m.\u001b[39;49mfill(BLACK)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/study/snake-ai-pytorch/the_game.ipynb#X13sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mfor\u001b[39;00m pt \u001b[39min\u001b[39;00m game\u001b[39m.\u001b[39msnake:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dev/study/snake-ai-pytorch/the_game.ipynb#X13sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         pygame\u001b[39m.\u001b[39mdraw\u001b[39m.\u001b[39mrect(display, BLUE1, pygame\u001b[39m.\u001b[39mRect(pt\u001b[39m.\u001b[39mx, pt\u001b[39m.\u001b[39my, BLOCK_SIZE, BLOCK_SIZE))\n",
      "\u001b[1;31merror\u001b[0m: display Surface quit"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import time\n",
    "WHITE = (255, 255, 255)\n",
    "RED = (200,0,0)\n",
    "BLUE1 = (0, 0, 255)\n",
    "BLUE2 = (0, 100, 255)\n",
    "BLACK = (0,0,0)\n",
    "\n",
    "BLOCK_SIZE = 20\n",
    "\n",
    "plot_scores = []\n",
    "plot_mean_scores = []\n",
    "total_score = 0\n",
    "record = 0\n",
    "game = SnakeGame(16, 9)\n",
    "agent = Agent(game)\n",
    "\n",
    "pygame.init()\n",
    "font = pygame.font.Font('arial.ttf', 25)\n",
    "display = pygame.display.set_mode((game.width * BLOCK_SIZE, game.height * BLOCK_SIZE))\n",
    "pygame.display.set_caption('Snake')\n",
    "\n",
    "\n",
    "\n",
    "def update_ui(game):\n",
    "    display.fill(BLACK)\n",
    "\n",
    "    for pt in game.snake:\n",
    "        pygame.draw.rect(display, BLUE1, pygame.Rect(pt.x, pt.y, BLOCK_SIZE, BLOCK_SIZE))\n",
    "        pygame.draw.rect(display, BLUE2, pygame.Rect(pt.x+4, pt.y+4, 12, 12))\n",
    "\n",
    "    pygame.draw.rect(display, RED, pygame.Rect(game.food.x, game.food.y, BLOCK_SIZE, BLOCK_SIZE))\n",
    "\n",
    "    text = font.render(\"Score: \" + str(game.score), True, WHITE)\n",
    "    display.blit(text, [0, 0])\n",
    "    pygame.display.flip()\n",
    "\n",
    "def average_of_last_n_items(lst, n):\n",
    "    # 边界情况：当n为0或负数时，返回None\n",
    "    if n <= 0:\n",
    "        return None\n",
    "    \n",
    "    # 边界情况：当列表为空时，返回None\n",
    "    if not lst:\n",
    "        return None\n",
    "\n",
    "    # 如果n大于列表的长度，使用整个列表\n",
    "    n = min(n, len(lst))\n",
    "    \n",
    "    # 使用切片获取末尾n项，并计算平均值\n",
    "    return sum(lst[-n:]) / n\n",
    "\n",
    "while True:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "\n",
    "    update_ui(game)\n",
    "    time.sleep(1)\n",
    "            \n",
    "    # get old state\n",
    "    state_old = agent.get_state(game)\n",
    "\n",
    "    # get move\n",
    "    final_move = agent.get_action(state_old)\n",
    "\n",
    "    # perform move and get new state\n",
    "    reward, done, score = game.play_step(final_move)\n",
    "\n",
    "    # clear_output(wait=True)\n",
    "    # game.render()\n",
    "    # time.sleep(0.01)\n",
    "\n",
    "    state_new = agent.get_state(game)\n",
    "\n",
    "    # train short memory\n",
    "    agent.train_short_memory(state_old, final_move, reward, state_new, done)\n",
    "\n",
    "    # remember\n",
    "    agent.remember(state_old, final_move, reward, state_new, done)\n",
    "\n",
    "    if done:\n",
    "        # train long memory, plot result\n",
    "        game.reset()\n",
    "        agent.n_games += 1\n",
    "        agent.train_long_memory()\n",
    "\n",
    "        if score > record:\n",
    "            record = score\n",
    "            agent.model.save()\n",
    "\n",
    "        print('Game', agent.n_games, 'Score', score, 'Record:', record)\n",
    "\n",
    "        plot_scores.append(score)\n",
    "        total_score += score\n",
    "        # mean_score = total_score / agent.n_games\n",
    "        mean_score = average_of_last_n_items(plot_scores, 20)\n",
    "        plot_mean_scores.append(mean_score)\n",
    "        plot(plot_scores, plot_mean_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
